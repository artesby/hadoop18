{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка песочницы с помощью Docker\n",
    "\n",
    "## Запуск\n",
    "\n",
    "#### 1. Устанавливаем `Docker` и запускаем консоль (под `Linux` для запуска следующих комманд нужны права суперпользователя)\n",
    "\n",
    "#### 2. Скачиваем контейнер с bigtop sandbox\n",
    "```bash \n",
    "docker pull bigtop/sandbox:1.2.1-ubuntu-16.04-hdfs_yarn_hive_pig        \n",
    "```\n",
    "\n",
    "#### 3. Запускаем, предварительно рекомендуется войти в директорию, куда склонирован git-репозиторий курса:\n",
    "\n",
    "```bash\n",
    "docker run -d --hostname=quickstart --name=hadoop-sandbox --privileged=true \\\n",
    "    -p 50070:50070 -p 14000:14000 -p 8088:8088 -p 19888:19888 \\\n",
    "    -p 9083:9083 -p 10000:10000 -p 10002:10002  \\\n",
    "    -v `pwd`:/course \\\n",
    "    bigtop/sandbox:1.2.1-ubuntu-16.04-hdfs_yarn_hive_pig\n",
    "```\n",
    "\n",
    "#### 4. Ждем некотое время, когда контейнер запустится, затем в консоли\n",
    "\n",
    "```bash\n",
    "docker exec -it hadoop-sandbox bash\n",
    "```    \n",
    "#### 6. В консоле\n",
    "```bash\n",
    "apt update -y & apt install -y python3 python3-pip hadoop-httpfs  \n",
    "service hadoop-httpfs start \n",
    "python3 -m pip install mrjob \n",
    "```   \n",
    "## Использование\n",
    "\n",
    "Контейнер можно остановить\n",
    "```bash\n",
    "docker stop  hadoop-sandbox\n",
    "``` \n",
    "\n",
    "и потом опять запустить\n",
    "```bash\n",
    "docker start  hadoop-sandbox\n",
    "```\n",
    "\n",
    "Если потребуется пробросить дополнительный порт или раздел, то можно сделать так - создать образ из существующего контейнера, удалить контейнер и запустить новый, указав дополнительные параметры:\n",
    "```bash\n",
    "docker stop hadoop-sandbox\n",
    "docker commit hadoop-sandbox hadoop-image\n",
    "docker rm hadoop-sandbox\n",
    "docker run -d --hostname=quickstart --name=hadoop-sandbox --privileged=true \\\n",
    "    -p 50070:50070 -p 14000:14000 -p 8088:8088 -p 19888:19888 \\\n",
    "    -p 9083:9083 -p 10000:10000 -p 10002:10002  \\\n",
    "    -v `pwd`:/course \\\n",
    "    hadoop-image\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После запуска контейнера на хост-системе можно проверить доступность сервисов:\n",
    "\n",
    "- http://localhost:50070 - HDFS WEB UI\n",
    "- http://localhost:14000 - HttpFS REST API\n",
    "- http://localhost:8088 - Resource Manager\n",
    "- http://localhost:19888 - Hadoop History Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
